%%%Template designed by Adam Glesser September 9, 2008
%%%All rights reserved (and deserved) 
%%%The only thing you should mess with on this line is the word problems.
%%%If this is a problem set, leave it as problems.
%%%If this is a solution set, change it to solutions.
\documentclass[12pt,solutions]{article}

%%%Here you should replace my name with your name
\newcommand{\prof}{Katie Henry \\ David Snyder \\ Adi Renduchintala}
%%%Make this your course number than leave it alone
\newcommand{\subj}{}
%%%Change the number 1 to which problem set you're on
\newcommand{\psnumber}{} %This is the Problem Set #
%%%Change the due date as needed
\newcommand{\duedate}{\date}  
%%%Change the topic as needed
\newcommand{\topic}{MLCD Project}


%%%%%%%%%%%%%%%You don't need to mess with anything in this section%%%%%%%%
\newif\ifisproblemset
\PassOptionsToClass{11pt,12pt}{article}
\DeclareOption{problems}{\isproblemsettrue}
\DeclareOption{solutions}{\isproblemsetfalse}
\ExecuteOptions{solutions}
\ProcessOptions\relax


\usepackage{amsmath, amssymb}
\usepackage{amsfonts}
\usepackage{multicol,parskip}
\usepackage{graphicx,booktabs}
\usepackage{tikz}
\usetikzlibrary{arrows,automata}
\usepackage{caption}
\usepackage{subcaption}
\usetikzlibrary{bayesnet}
\setlength{\oddsidemargin}{0pt} \setlength{\evensidemargin}{0pt}
\setlength{\textwidth}{6.5in} \setlength{\topmargin}{-.5in}
\setlength{\textheight}{8.5in}

\newlength{\toppush}
\setlength{\toppush}{2\headheight} \addtolength{\toppush}{\headsep}

%%%This command makes the title. Don't mess with it, unless you want to change the name Problem Set
%%%or Solution to Problem Set to something else.
\newcommand{\htitle} 
{
    \noindent\vspace*{-\toppush}\newline\parbox{6.5in}
    {
        \vspace{-.85cm}
        \prof\hfill \ 
	 \today
	\vspace*{-.5ex}\newline
        \mbox{}\hrulefill\mbox{}
    }
    \vspace*{1ex}\mbox{}\newline
    \begin{center}{
        \large\bf{Progress Report} }\end{center}
}

%%%This command makes the headers. Don't mess with it.
\newcommand{\handout}
{
    \thispagestyle{empty}
    \markboth{\topic}{\topic}
    \pagestyle{myheadings}
    \htitle
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%This next section contains custom macros%%%%%%%%%%%%%%%%%%
%If these don't fit your course, remove them and add your own


%This first one allows you to write limits faster. It takes 4 inputs:
%The variable, what it's approaching, if relevant which side and the function.
%For example, if you wanted to write the limit as a x goes to 3 from the left 
%side of the function x^2 + 3, you would write $\limit{x}{3}{-}{x^2+3}$. If 
%you didn't care about which side you would leave the third set of braces empty, i.e.,
%$\limit{x}{3}{}{x^2+3}$.
\newcommand{\limit}[3]{\lim\limits_{#1 \rightarrow #2}\ #3}

  
%This is a slightly faster way of writing derivatives. It takes 2 inputs:
%The first is the function your differentiating, the second is the variable 
%with respect to which you're differentiating. For example, if you want to
%write the the derivative of y with respect to x, you would type $\d{y}{x}$.
\renewcommand{\d}[2]{\dfrac{\mathrm{d}#1}{\mathrm{d}#2}}  

%This last macro creates a multicolumn list environment where the first input is the number of columns.
%Use this command when you plan on having so many parts to a problem, with each being very short to state
%that you would like to put the problems in several columns. An example of the syntax would be 
%\multilist{3}{
%\item first item
%...
%\item last item
%}
%This will create a list that displays in 3 columns. The 3 can be replaced by any natural number, but 2 and 3
%are the only one numbers likely to give readable output.
\newcommand{\multilist}[2] 
    {
        \begin{multicols}{#1}
            \begin{enumerate}
                #2
            \end{enumerate}
        \end{multicols}
    }
%%%For solutions sets:
%%%After you write the problem, the next line should be
%%%\solution{Type your solution in here}
\newcommand{\solution}{ 
  \medskip
  {\bf Solution:}
}     

\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\dx}{\frac{\delta}{\delta x}}
\newcommand{\ab}{\mathbf{a}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\Y}{\mathbf{Y}}
\newcommand{\bA}{\mathbf{A}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\Xs}{\tilde{\mathbf{X}}}
\newcommand{\xs}{\tilde{\mathbf{x}}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\sx}{\bar{\x}}
\newcommand{\tb}{\mathbf{t}}
\newcommand{\SG}{\mathbf{\Sigma}}
\newcommand{\ts}{\theta^*}
\newcommand{\tbi}{t_{b_i}}
\newcommand{\ptb}{\hat{t}_b}
\newcommand{\tv}{t_v}
\newcommand{\tvi}{t_{v_i}}
\newcommand{\ptv}{\hat{t}_v}
\newcommand{\ps}{\hat{s}}
\newcommand{\yh}{\hat{y}}
\newcommand{\M}{\mathbf{M}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\T}{\mathbf{T}}
\renewcommand{\S}{\mathcal{S}}
\renewcommand{\th}{t_0}
\renewcommand{\v}{\mathbf{v}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\W}{\mathbf{W}}
\newcommand{\p}{\mathbf{p}}
\newcommand{\wh}{\hat{\mathbf{w}}}
\newcommand{\wht}{\hat{\mathbf{w}}^T}
\newcommand{\whs}{\hat{\tilde{\mathbf{w}}}}
\newcommand{\whst}{\hat{\tilde{\mathbf{w}}}^T}
\newcommand{\ws}{\mathbf{w}^*}
\newcommand{\wst}{\mathbf{w}^{*T}}
\newcommand{\at}{\mathbf{a}^{T}}
\newcommand{\hth}{\hat{\theta}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\dbphi}{\Delta\bphi}
\newcommand{\C}{\mathbf{C}}
\newcommand{\gd}{\nabla}
\newcommand{\hs}{\nabla^2}
\newcommand{\Cb}{\bar{C}}
\renewcommand{\labelenumi}{\arabic{enumi})}
\renewcommand{\labelenumii}{\alph{enumii})}
\providecommand{\norm}[1]{\lVert#1\rVert}

\newcommand{\solutionline}{
\begin{center}
\line(1,0){400}
\end{center}
}
    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%This is where the document begins%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  
\begin{document}


%%%%%This stuff puts in the header and changes some spacing%%%%%%
\handout

\setlength{\parindent}{0pt}

The overall goal of this project is to develop a method for early detection of septic shock using continuous physiological data. We divide the problem into three parts: use topic modeling to learn features from the physiological data, derive a decision policy to decide what if any state the system should predict, and use a neural network to estimate the posterior probabilities for each state.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%Here is where the actual math begins%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{section}{0}
\section{Feature Discovery}
\subsection{Problem Definition}
The goal of this section is to detect hidden states over the time-series data for each patient, that would augment features being used by subsequent prediction systems. A natural model for such a system is the HMM. Using these hidden state sequences as input tokens of a document, we intend to run Topic models over all the patient records to see if there is any groups of states or any patten in state sequences that either explain or help predict the onset of septic shock.
\subsection{Related Works}
As noted in our proposal, the prognosis of septic shock in critically ill patients has a lot of variability. There is no single monolithic notion of septic shock \cite{Shavdia2007} . There are several methods to approach feature discovery in time series data of this nature. \cite{Esbroeck2012hrt}  applied symbolic aggregate approximation SAX \cite{Lin2003sax} on physiological time series data. More recently, Time series topic models have also been developed, \cite{SariaThesis2011} these work directly on continuous time domain signals and extract latent motifs. In our approach, we would like to investigate an HMM based approach, to allow a hidden state to emit a vector observation for a single time instance, where each element in the observation vector represents the observation of each channel of data (ECG, blood pressure, oxygen saturation etc).
\subsection{Contribution}
The dataset contains patient heart rate data at a frequency of 2 Hz. Each sample has been obtained by computing statistics over a 2 minute window from a the original heart rate data. Thus, every 120th sample represents statistics from a non-overlapping region from the original data. The first task is to extract these samples per patient record. We intend to find hidden states that best explain this lower resolution data. Each state of our HMM model will cover a wider time window, our current estimate for length of observation window per state is 10 minutes.\\
We also intend to extend the HMM to a coupled HMM where the second set of observations would represent blood pressure, temperature or oxygen saturation. Ideally the second set of observations would be in close time sync with the Heart rate data. This would be a factor in deciding which data stream (temperature, blood pressure or oxygen saturation) we would use for the second observation layer in the coupled HMM. Another factor would be the availability of these streams for all patient records. \\
\subsection{Learning Problem}
We propose to learn a HMM and then extend it to a coupled HMM. The 2 layers of observation are heart rate and blood pressure, temperature or oxygen saturation.  We intent to learn the states sequence that would best explain the patient records. Below is a representation of this coupled HMM, with each variable defined.\\
\begin{figure}[ht]
  \begin{center}
    \begin{tabular}{cc}
      \input{coupled_hmm}
    \end{tabular}
  \end{center}
  \caption{Coupled HMM model}
\label{fig:coupled_hmm_fig}
\end{figure}
\begin{align*}
O^1 &= o^1_{0}, \ldots,o^1_{T},   \text{sequence of heart rate observations (statistics from a 10 min time window)}\\
O^2 &=o^2_{0}, \ldots,o^2_{T},  \text{sequence of blood pressure or oxygen saturation}\\
Z &=  z_{0}, \ldots,z_{T}, \text{sequence of ${O^2}$ related states}\\
Y &=  y_{0}, \ldots,y_{T},  \text{sequence of ${O^1}$ related states}\\
\end{align*}
For this project deliverables, this model has been scaled down to a single HMM. Experiments were done to infer the feasibility of extracting useful information for prediction.\\
\subsubsection{State Priors}
The goal in this section is to provide an initial transition structure of the HMM model. The transition structure is can be depicted by figure 2.This automata shows that each patient starts from one of $n$ possible $Pre$ states. The $Pre$  states can be thought of as 'healthy' states before the $Onset$ of any of the 3 conditions that are being modeled. Of course there is no real 'healthy' state since all the records are from patients in the ICU. From each of the $Pre$ states the model can transition of any of the other $Pre$ states or it can transition to the $Onset$ state. This state, as the name suggests, is the onset of the condition being modeled. For a 'Sirs' patient , this state would signify the patterns in heart rate just before the a clinician can assign the label of 'Sirs' to the patient. This transition model suggests that once a patient is in the $Onset$ state they will continue to remain here until the $Post$ state. The $Post$ state can be thought of a the observations of patient heart heart just after they have been identified with one of the 3 conditions.
In the current model, a state can emit observations of a 10 minute window. Since the data has been down sampled to 1 sample per minute this results in each state benign a 10 dimensional mean vector, and a 10x10 dimensional covariance matrix.
\begin{figure}
\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
                    semithick]
  \tikzstyle{every state}=[fill=white,draw=gray,text=black]

  \node[initial,state] (A)                    {$init$};
  \node[state]         (Pre2) [right of=A] {Pre1};
  \node[state]         (Pre1) [above of=Pre2] {Pre2};
  \node[state]         (Pre3) [below of=Pre2] {Pre3};
  \node[state]         (Onset) [right of=Pre2] {Onset};
  \node[state]         (Post) [right of=Onset]  {Post};

  

  \path (A) edge        node {$s$} (Pre1)
            edge              node {} (Pre2)
            edge              node  {}(Pre3)
        (Pre1) edge [loop above] node {$p$} (Pre1)
            edge  [bend left]node {$p$} (Pre2)
            edge  [bend left] node {$p$} (Pre3)
            edge  node {$o$} (Onset)
         (Pre2) edge [loop above] node  {}(Pre2)
            edge  node{} (Pre1)
            edge   node {} (Pre3)
            edge  node  {}(Onset)
         (Pre3) edge [loop below] node{}(Pre3)
            edge  [bend left]node  {}(Pre2)
            edge  [bend left] node{} (Pre1)
            edge  node{}  (Onset)
        (Onset) edge [loop above] node {$po$} (Onset)
        (Onset) edge  node {$po$} (Post)
        (Post) edge  [loop above] node {$e$} (Post);
\end{tikzpicture}
\end{center}
 \caption{Initial transition structure of HMM model}
\end{figure}
Using appropriate initial values for states is crucial to restrain the system from straying away from what might be explanatory data. We intend to encode some of our prior intuitions in this model in the following manner. Let ${Y}$ represent the states for heart rate observations over the patient record. We have the following insights from the data that we would like to encode.\\
1. Bootstrap from Patient Records: Each patient record has a time stamp representing the presence of SIRS, Sepsis, Severe Sepsis or Septic Shock. While this time stamps are not exact (that is, they are marked when the clinician happens to observe the symptoms and there is no guarantee that it was the precise moment of onset) we can still get statistics from the time region surrounding the clinicians observation of the symptoms. Using this technique we can get good initial guesses for statistics (such as means, and variances i.e. modeling the observation as a Guassian) for 4 states. It might also be preferable to model the observation given the state as a Beta distribution as we know that Heart rate can never be negative (which a gaussian in theory will allow).\\
2. Low Heart Rate Variability: Apart from the 4 states with we intend to bootstrap our model with states that have priors to restrict their parameters. One of the key insights regarding the onset of septic shock is reduction in heart rate variability. This informs us that one of the statistics that we need to compute from each 10 min time window should be a good indication of variability. Thus, simply getting mean heart rate for a 10 min duration would not be a good statistic. We intend to initialize a "Low Variability" state to capture this trend.
3. High Heart Rate Variability: The opposite state from the pervious would be the "High Variability" state where the 10 min window shows significant variation.\\
4. Reduction in Variability State: This state would be initialized such that there is variability across the earlier samples which slowly decline as we reach the end of the time window. One way to achieve this is to place a prior over the slope of a statistic such as change in variable from beginning of window to the end. A negative slope indicates reduction of variability.\\
\subsubsection{Model Training}
One way to capture all of these aspects is to initialize the mean and covariances of these states directly from the data. The $Pre$ states got their mean and variances from the first 10 min of data from each patient. The assumption here is that the beginning of a patient record is the time when they are relatively 'healthy' compared to the rest of their trajectory. In the figure above multiple $Pre$ states are shown, this is achieved by  perturbing the mean and setting it as the initial value for another state. This way the HMM can be modeled with an arbitrary number of states. The $Onset$ mean and covariance was obtained by computing the mean and covariance of 10 min windows just before the disease time stamp. The same was done to obtain the $Post$ state, except this represents the 10 min time window just after the disease label. We found that the initial states, actually did not appear to capture these trends. Since they were obtained by average across all patients with a particular disease condition, but after few iterations of EM over the model the mean values of the states seemed to show distinct forms.\\
%%%%%%%%
%% Show before after em states here
%%%%%%%%%

In the figure above (left) we see the means for 6 possible $Pre$ states for the Sirs condition. After 20 iterations of EM over the model we see the states each take on a specific characteristic(above right). 2 of the states represent high heart rate deviations, while 2 other represent low heart rate deviation. The most interesting states are those that capture the interesting changes in the heart rate. The Green line shows a 10 min window where the heart rate deviation is dropping and the purple line captures the opposite trend. With longer time windows it might be possible to capture more interesting patterns in this data.\\

Selection of number of states and selection of number of iterations are currently arbitrary. They both represent the extent to which the HMM models the training data. Increasing number of states and increasing the number of iterations could both lead to over fitting to the training data. To study to the performance of the model while keeping this is mind, a number of models each with different number of states and different number of iterations where trained. Thus each condition model (Sirs, Severe Sepsis and Septic Shock) 
the number of states ranged from 4 to 20, and the number of iterations from 2 to 100. 
\subsubsection{Evaluation}
Each trained state represents a characteristic trajectory over the window of observation.  Given a new observation sequence we can compute the best sequence of states that can be assigned to the observation sequence. This is also in a sense representing the original heart rate deviation as a series of interpretable states. But what is the predictive power of these model? After all any data will be fit by the EM algorithm as much as it can, and this will automatically result in a number of states. But how meaningful are these states in the context of prediction?\\
In an attempt to answer these questions, we tried to predict the instances of Septic Shock Vs Severe Sepsis Vs Sirs in the development data set. The assumption here is that each of these condition will have subtly different trajectories that can be detected before the onset stage. These subtle differences in trajectories should be captured by the Pre states of each model. Given a new unseen observation sequence, we can compute its forward probability under a model.  We choose the forward probability instead of the Viterbi probability because the Viterbi probability only represents the best state sequence, while forward probability is the sum of all possible state sequences a model can assign to the observation. A model that more closely fits the data would have higher forward probability.\\

A unseen development data set was created. Each condition model model that was trained was allowed to 'see' the initial observations of the unseen data. The range of initial observation were from 0-10 minutes, all the way to 0-1000 minutes in 20 minute increments. Using each initial observations a winning model was picked based on forward probability of the observation under that model. For example for patient 'A' the first 10 minutes of data was passed thought the Sirs, Severe Sepsis and Septic Shock models, if the Septic Shock model recorded that highest forward probability then its equivalent to predicting that patient 'A' is more likely to get Septic Shock. Clearly is more more the observation sequence is seen by each model, more reliable the forward probability estimates would be (in terms of relative likelihood). This trend is confirmed below by the plot of precision and recall of prediction of each model.

%%%%%%%%%%
%% insert precision recall plot here
%%%%%%
We can see that when small amounts of the observation is shown to each model (< 200 min) there is lot of fluctuation in the prediction. This makes sense because there is not enough data to get a reliable forward probability estimate. There is more chance of a model getting lucky since is just happened to have a state or two that matches closely with the small portion of data seen. We see that as the observations shown to the models increases there is more consistent prediction. Not only is the prediction more consistent, we also see fairly high precision and recall for 2 of the 3 conditions. The prediction of Septic Shock was made with a precision of ~0.7 and a recall of ~0.65, given that this is a three way prediction these represents accuracy substantially above chance. The figure was obtained by using models trained with 15 states and training was truanted at 100 iterations.\\

\subsubsection{Discussion}
We can also see that Severe Sepsis was never predicted. This results in very poor precision and recall for that class. This also makes sense because this condition is like a intermediate condition between Sirs and Septic Shock. This frame could not easily learn the subtle differences that separate Severe Sepsis from Sirs and Septic Shock.

\section{Reliable Classification}

\subsection{Problem Definition}
\begin{figure}[ht]
  \begin{center}
    \begin{tabular}{cc}
      \input{model_reclas}
    \end{tabular}
  \end{center}
  \caption{Reliable Classifier model as a Bayesian network}
\label{fig:reclas_bnet}
\end{figure}


\begin{align*}
X &= x_0, x_1, \ldots, x_T \text{ sequence of observations}\\
R &= r_0, r_1 \ldots, r_T \text{ sequence of clinical interventions}\\
\hat{Y} &= \yh_0, \yh_1, \ldots, \yh_T \text{ sequence of predicted class labels, $\yh_i \in \{1,\ldots, C\}$}\\
Y&=y_0,y_1,\ldots,y_T \text{ sequence of true labels, $y_i \in \{1,\ldots, C\}$}\\
U&=u_0,u_1,\ldots,u_T \text{ a decision policy, $u_i \in \{1,\ldots, C, C+1\}$}\\
S &\in \R^{C+1 \times C \times T}, S_{i,j}^{(t)} \text{ is the cost of choosing label $i$ instead of label $j$ at time $t$}\\
\bar{C} &= \{1,\ldots, C\} \text{ set of possible classes}\\
\hat{C} &= \{1,\ldots, C,C+1\} \text{ set of possible decisions}
\end{align*}

Our goal is to learn a decision policy that allows us to make the optimal decision at time $T$ given a sequence of observations and a user-defined cost function.

At each time $t$ the system either chooses the class $c \in \{1,\ldots, C\}$ that minimizes the expected loss over the time sequence $0\ldots T$ or it refuses to make a decision, corresponding to choosing $c = C+1$. Each $\yh_t$ is a probability distribution over possible the possible classes $\bar{C}$. If there is a clinical intervention $r_t$ at the current time $t$, e.g.\ a doctor prescribes pressors or performs some other action that provides a diagnosis, we define $P(y_t=j)$ to be $P(y_t=j|r_t)$. However, since we are performing a continuous monitoring task, the majority of time points will not have a clinical intervention associated with it. In these cases we use the distribution from the classifier $\yh_t$ and define $P(y_t=j)$ to be $P(\yh_t=j|x_t, y_{t-1})$. We then feed the distribution $y_t$ to our classifier so that the predicted distribution over classes $\yh_{t+1}$ incorporates knowledge about clinical interventions into the classification process. Instead of defining the distribution $y_t$ as either $r_t$ or $\yh_t$, we could instead define it as a mixture of the two distributions based on our confidence in the classifier's predictions. 

The decision $u_t$ is influenced by the distribution over all possible class labels $y_t$ and the previous decision $u_{t-1}$. The motivation for allowing the previous decision to influence the current decision is two-fold. First this can act as a smoothing function and capture the intuition that patients show a gradual transition from one disease state to the next, and prevents situations like repeatedly alternating between two disease states instead of staying in one state until the classifier is sufficiently confident to advance to a new disease state. The second benefit of this dependency between successive decisions is that it allows us to prevent overly long rejection periods, where the classifier continuously refuses to predict. We can do this by progressively down-weighting the probability of rejection given the history of rejection.

\subsection{Related Work}

By adding the notion of rejection (i.e.\  refusing to predict), the classifier is able to avoid misclassification, by instead refusing to predict. As stated by Chow \cite{Chow1970} the optimal strategy is one that minimizes the rate of rejection. For a single time point, Chow shows how to formulate the decision policy of when to reject in terms of a rejection threshold. He similarly formulates the error in terms of that same threshold by noting that the expected cost of error is the expected cost of rejecting minus the expectation of being correct. This rejection threshold can then relate the expected cost of rejecting to the expected cost of misclassification and allow the user to trade off between them. 

Grall-Ma\"{e}s and  Beauseroy \cite{GrallMaes2009} extend the optimal decision framework by allowing an observation to be assigned to a subset of the classes. Assigning an observation to the set of all classes corresponds to refusing to predict and assigning an observation to a set with only one class corresponds to predicting that class without ambiguity. Grall-Ma\"{e}s and  Beauseroy derive the optimal decision policy for assigning an observation to a set given a cost matrix and performance constraints. Performance constraints are, for example, the false positives for this class must be below a given threshold or the false positives for a given subset must be below this level.

Santaniello et al.\ \cite{Santaniello2012} formulate a transition detection problem where they learn a decision policy to decide when a change of state has occurred in a time sequence. In particular, they derive a decision policy for quickest detection, where they want to detect the change point as early as possible with sufficient confidence. To encourage early detection, they include the expected distance of the current time from the actual change time in the cost function. 


\subsection{Contribution}
For the task of sepsis prediction and continuous patient monitoring in general, we want to derive a generic optimal decision policy for time series data where we allow the system to refuse to predict. Moreover, we allow for a user-defined cost function that can be asymmetric, e.g.\ assigning different costs for false positives or negatives for different classes, and that can change over time. This task is different than transition detection in that we do not assume there is only one transition point and we do not assume that the subject even has to transition.


\subsection{Simulation}

In order to test the reliable classification, we generate synthetic data from four overlapping Gaussians, where each Gaussian corresponds to a different class.

We use Kevin Murphy's BayesNet and CRF Matlab toolkits to implement a model to compute $\hat{Y}$ for the synthetic data. We then use these marginal probabilities at each time step to implement the learning problem as described below. For the simulation we do address the situation where we have a doctor intervention (i.e.\ $R=\emptyset$). 

We will consider how different parameterizations of the cost matrix allow us to trade off between the cost of misclassification and the cost of refusing to predict. We will also investigate how to set the cost matrix to encourage early detection.

\subsection{Learning Problem}
Our goal is to learn a decision policy that allows us to minimize the expected loss over the entire time sequence of observations.
The expected posterior loss at time $t$ of making decision $u_t=i$ given that the true label is $y_t=j$ and the previous decision was $u_{t-1}=h$ as follows:

\begin{align}
\E[L(u_t|y_t, u_{t-1})] &= \min_{u_t} \Big\{ \sum_{i \in \hat{C}} \sum_{j \in \bar{C}} S_{i,j}^{(t)} P(y_t=j)P(u_t=i|u_{t-1})\I(u_t=i)\Big\}\\
&= \min_{u_t \in \hat{C}} \Big\{ \sum_{j \in \bar{C}} S_{u_t,j}^{(t)} P(y_t=j)P(u_t|u_{t-1})\Big\}
\label{eqn:exploss}
\end{align}

We use dynamic programming to learn the optimal decision policy over the time sequence, with a discounting factor $\beta \in [0,1]$ to adjust the importance of past observations.

Let $V(y_T)$ be the value of the expected posterior loss minimized by a decision policy $\{u_t\}_{t=0}^{T}$. At time $T$ we make the decision $u_T$ that is the argmin of (\ref{eqn:bellman}).

\begin{align}
V(y_T) &= \min_{\{u_t\}_{t=0}^{T}} \Big\{ \sum_{t=0}^T \beta^{T-t}\E[L(u_t|y_t, u_{t-1})] \Big\}\\
&= \min_{u_T \in \hat{C}} \Big\{  \beta^{0}\E[L(u_T|y_T, u_{T-1})] + \min_{\{u_t\}_{t=0}^{T-1}} \beta \sum_{t=0}^{T-1} \beta^{T-1-t}\E[L(u_t|y_t, u_{t-1})] \Big\}\\
&= \min_{u_T \in \hat{C}} \Big\{  \E[L(u_T|y_T, u_{T-1})] + \beta V(y_{T-1})\Big\} \label{eqn:bellman}
\end{align}

From this we see that the system will either make the decision $u_T = c \in \bar{C}$ that minimizes the expected loss over the sequence or it will refuse to predict, equivalent to choosing $u_T = C+1$. 

Computing the expected loss with dynamic programming, where we maintain a vector of the class costs from the previous time step, requires $C(C+1)+4$ operations at each time point, so the overall complexity is $O(TC^2)$. For space efficiency, it is only necessary to maintain the cost vector from the previous time step.


\section{Neural Networks for Sepsis Prediction}

\subsection{Introduction}

\begin{figure}[h!]
  \caption{Schematic of a simple neural network}
  \centering
    \includegraphics[width=1.0\textwidth]{nn_plots/nn}
\end{figure}

The goal of this section is to train neural networks to estimate the probability of developing a disease state given a sequence of
physiological data. Here, the task is early prediction of septic shock in ICU patients with a documented infection. Heart rate is used as input to the neural network. We estimate the probability of an ICU patient developing a form of sepsis $P(sepsis \mid S)$ where $S$ is a window of the 
heart rate timeseries. This model is motivated by the state of the art performance produced by Deep Neural Networks in a number of domains.


\subsection{Related Work}

The application of neural networks to the the task of sepsis prediction appears relatively unexplored. However, neural network techniques have been successfully applied to classification and prediction on other physiological time series. \cite{wulsin2011modeling} applied Deep Belief Networks (DBNs), a method related to Deep Neural Networks (DNN), to the task of anomaly detection in clinical EEG records. The group found that 
DBNs produced comparable results to other state of art methods, but significantly faster. They found
that using the raw EEG waveform showed improved performance in an
anomaly detection task over engineered features.
These results underscore the advantage of deep learning methods in 
automatically uncovering useful features. \\

To obtain adequate performance a body of techniques and tricks need to be considered. In \cite{hinton2012deep} speech recognition groups at Google, Microsoft, IBM and University of Toronto share various techniques for improving neural network performance. For instance, one should consider techniques for
preventing overfitting by certain restrictions on weight updating and smart initialization of weights.

\subsection{Approach}

Equation (6) describes
the output of a neuron $j$ given the weighted commulative input $x_j$ (7). 
\begin{align}
y_{j} = \frac{1}{1+e^{-x_{j}}} \\
x_{j} = b_{j} + \sum_{i}y_{i}w_{ij} \\
p(sepsis \mid S) = \frac{1}{1 + exp(x_{sepsis})}
\end{align}

\begin{align}
J = -\sum_{j} t_{j} log(y_{j})
\end{align} \\
\\
\begin{align}
\nabla J(w) = -\sum_{j} (y_{j} - t_{j}) x_{j} \\
input = \bar{x}_{1}, \sigma_{1}, \bar{x}_{2}, \sigma_{2}, ... ,\bar{x}_{60}, \sigma_{60}
\end{align} \\

Equation (8) represents the probability
of sepsis given some some sequence of physiological signals $S$. With only two classes, this is equivalent to the
\textit{softmax} function. The 
target function is (9) where $t_{j}$ is the correct class label (eg, sepsis or not sepsis). Equation (10)
is the derivative at the output layer. Input to the network is a one hour frame in the form of a 2x60 vector of mean heart rate $\bar{x}$
and heart rate standard deviation $\sigma$. Each statistic is measured from a one minute interval in the original 2 Hz data.
\begin{align}
\eta = \frac{A}{\frac{epoch_{j}}{epoch_{max}} + 1} \\
w_{i,j} \sim N(0, \frac{1}{\sqrt{inputs_{j}}}) \\
w_{i,j} \leftarrow \frac{w_{i,j}}{\sigma_{j}}
\end{align}
\\
Neural networks require careful weight initialization, pretraining (for deep networks), topology and other considerations described in \cite{vesely2013sequence, hinton2012deep}. To help guarantee convergence, we have a learning rate which decreases as the number of epochs increase (12). Weights are drawn from a normal distribution (13), which we found offered greater stability over alternative distributions, such as uniform. After two or three hidden layers, the network suffers from oversaturation, which is characterized by a very large range of values from the
transfer functions in (8), resulting in numerical overflow and underflow. To combat this issue, we simply divide by the standard deviation
of the weights in the oversaturated layer during training (14).
\\
We use a standard batch gradient descent backpropagation algorithm to train the network. We experimented with stochastic gradient descent and didn't
notice much of an advantage. Moreover, it's easier to track the training process in batch gradient descent: at each epoch, we calculate
the loss function (9) and in the batch variation, we can be sure that the network's parameters have been altered by every training example.

\subsection{Preliminary Results and Evaluation}

\begin{figure}
        \centering
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/loss2}
                \caption{Cross entropy loss vs. number of epochs.}
                \label{fig:entropy}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/dev2}
                \caption{Development (validation) set error rate vs. number of epochs.}
                \label{fig:dev}
        \end{subfigure}
\caption{Typical results for a network with 120 input nodes, 1 hidden layer with 100 nodes, and one output layer with 1 node.}\label{fig:loss_dev}
\end{figure}

In figure \ref{fig:loss_dev} we present typical results for a network with 120 input nodes, 1 hidden layer with 100 nodes, and a single output layer with 1 node. Given the current framework, we didn't see an advantage in using more than 1 hidden layer. The development (validation) error rate
in ~\ref{fig:dev} is the classification error rate. To obtain classification from the conditional probabilities generated by the network, we
map probabilities at or above 0.5 to class 1, and probabilities below 0.5 to class 0.
\\
\\
To train the network in figure ~\ref{fig:loss_dev} we do not use a sliding window over the entire time series for each patient. Instead, we 
first separate the data into two categories: SIRS, and severe sepsis and septic shock. From the SIRS category we randomly select some
number of 1 hour frames. From the severe sepsis and septic shock category, we only select the one hour frames which immediately precede 
the onset of the disease. While this setup isn't ideal, it plays an important step in the goal of more sophisticated prediction, by
demonstrating that we can distinguish between certain disease states by using just heart rate.

\begin{figure}
        \centering
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/probs_c0_1}
                \caption{}
                \label{fig:c0_0}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/probs_c1_2}
                \caption{}
                \label{fig:c0_0}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/probs_c0_3}
                \caption{}
                \label{fig:c0_0}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/probs_c1_3}
                \caption{}
                \label{fig:c0_0}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/probs_c0_4}
                \caption{}
                \label{fig:c0_0}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/probs_c1_4}
                \caption{}
                \label{fig:c0_0}
        \end{subfigure}
\caption{Probability of sepsis from beginning to end of individual dev (validation) records. The left column (blue) corresponds to patients who only have SIRS, while the right column (red) corresponds to those who develop either severe sepsis or septic shock by the end of the time series. These results are due to a network with 120 input nodes and 100 hidden layer nodes.}\label{fig:probs}
\end{figure}
The goal of this section is the early prediction of septic shock, rather than just the classification of it in static window. Figure ~\ref{fig:probs}
illustrates preliminary results for this task. In each patient, we slide a window over the time series, and generate $p(sepsis \mid frame)$. Before calculating these probabilities, the network was trained using the techniques discussed in the previous session. Further, results were
only reported for networks which achieved an error rate of .30 or less on the dev set (see ~\ref{fig:dev}). 
\\
\\
Ideally, we would like to see that the $p(sepsis \mid frame_{t})$ increases over time for the patients with severe sepsis and septic shock
and remains relatively constant for patients with SIRS. Additionally, it would be desirable for the $p(sepsis \mid frame_{t})$ to be 
higher in general for those who go on to develop septic shock or severe sepsis than those who develop SIRs. Given our preliminary
data, it is unclear if we can affirm either of these statements.   

\subsection{Discussion}

In \textit{Approach} we describe that the input to the network is a one hour frame of mean heart rate and heart rate standard deviation.
The two features are extracted from 1 minute intervals in the original heart rate. Initially, we attempted to use the raw 2 Hz heart rate directly,
but this suffered from slow training and near chance dev set accuracy. We also extracted these features at intervals of 
15 and 7.5 minutes. Due to such extreme downsampling, the data was much faster to process, but accuracy was no better than chance. Experimentally, we found that features extracted at one minute intervals retained enough structure in the data for learning to occur (see \textit{Preliminary Results}) while being computationally tractable.
 
\subsection{Future Work}

We observed numerical instability and overfitting in networks with several layers. However, we never implemented the sophisticated pretraining
methods characteristic of DNNs. After incorporating these techniques, we will explore what, if any, advantage deep neural networks provide
us in this domain.
\\
\\
Our current framework can accurately classify a one hour frame of heart rate as septic or not septic when the input is unambiguous. However,
when used to predict the future onset of sepsis, results under this system are inconclusive (see \textit{Preliminary Results}).
\\
\\
It is possible that heart rate alone doesn't have enough structure to adequately predict septic shock hours in advance. We will incorporate
additional physiological signals, such as blood pressure and respiratory rate as features to the neural network.

\subsection{Data}

The data for this task consists of heart rate sampled at 2 Hz derived from the MIMIC II Waveform Database. For neural network training, we use a 486 record subset which 
serves as the training, dev, and test sets. 
Each record contains heart rate for an ICU patient with SIRS, severe sepsis or septic shock, with at least
12 hours preceding the event.

\section{Discussion and Future Work}

In this project we used heart rate exclusively to distinguish between sepsis states. However, results from the HMM tagger demonstrate
that while it is possible to distinguish between SIRS and the septic shock, it is difficult to distinguish between the different types
of sepsis (eg, severe sepsis and septic shock). Physiological data has predictive power, but additional representations and possibly additional signals may be beneficial. For instance, early predictive ability of the neural network may be applified by augmenting  heart rate with respriratory rate and blood pressure.
\\
\\
Integration of the three components of this project is an important, but currently unmet goal of this project. Ideally, each component of
this project will interact with eachother in a pipeline. For instance, the HMM tag sequence can be interpreted as categorical features and 
input to the neural network. Alternatively, the probability of observation sequence under each HMM model can be directly used as input into
the decision policy system. The output of the neural network are conditional probabilities which can serve as input into the decision policy 
system.

\bibliographystyle{plain}

\bibliography{PhysMod,dnn,ref}

\end{document}
