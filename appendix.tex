%%%Template designed by Adam Glesser September 9, 2008
%%%All rights reserved (and deserved) 
%%%The only thing you should mess with on this line is the word problems.
%%%If this is a problem set, leave it as problems.
%%%If this is a solution set, change it to solutions.
\documentclass[12pt,solutions]{article}

%%%Here you should replace my name with your name
\newcommand{\prof}{Katie Henry \\ David Snyder \\ Adi Renduchintala}
%%%Make this your course number than leave it alone
\newcommand{\subj}{}
%%%Change the number 1 to which problem set you're on
\newcommand{\psnumber}{} %This is the Problem Set #
%%%Change the due date as needed
\newcommand{\duedate}{\date}  
%%%Change the topic as needed
\newcommand{\topic}{MLCD Project}


%%%%%%%%%%%%%%%You don't need to mess with anything in this section%%%%%%%%
\newif\ifisproblemset
\PassOptionsToClass{11pt,12pt}{article}
\DeclareOption{problems}{\isproblemsettrue}
\DeclareOption{solutions}{\isproblemsetfalse}
\ExecuteOptions{solutions}
\ProcessOptions\relax


\usepackage{amsmath, amssymb}
\usepackage{amsfonts}
\usepackage{multicol,parskip}
\usepackage{graphicx,booktabs}
\usepackage{tikz}
\usepackage{caption}
\usepackage{subcaption}
\usetikzlibrary{bayesnet}
\setlength{\oddsidemargin}{0pt} \setlength{\evensidemargin}{0pt}
\setlength{\textwidth}{6.5in} \setlength{\topmargin}{-.5in}
\setlength{\textheight}{8.5in}

\newlength{\toppush}
\setlength{\toppush}{2\headheight} \addtolength{\toppush}{\headsep}

%%%This command makes the title. Don't mess with it, unless you want to change the name Problem Set
%%%or Solution to Problem Set to something else.
\newcommand{\htitle} 
{
    \noindent\vspace*{-\toppush}\newline\parbox{6.5in}
    {
        \vspace{-.85cm}
        \prof\hfill \ 
	 \today
	\vspace*{-.5ex}\newline
        \mbox{}\hrulefill\mbox{}
    }
    \vspace*{1ex}\mbox{}\newline
    \begin{center}{
        \large\bf{Progress Report} }\end{center}
}

%%%This command makes the headers. Don't mess with it.
\newcommand{\handout}
{
    \thispagestyle{empty}
    \markboth{\topic}{\topic}
    \pagestyle{myheadings}
    \htitle
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%This next section contains custom macros%%%%%%%%%%%%%%%%%%
%If these don't fit your course, remove them and add your own


%This first one allows you to write limits faster. It takes 4 inputs:
%The variable, what it's approaching, if relevant which side and the function.
%For example, if you wanted to write the limit as a x goes to 3 from the left 
%side of the function x^2 + 3, you would write $\limit{x}{3}{-}{x^2+3}$. If 
%you didn't care about which side you would leave the third set of braces empty, i.e.,
%$\limit{x}{3}{}{x^2+3}$.
\newcommand{\limit}[3]{\lim\limits_{#1 \rightarrow #2}\ #3}

  
%This is a slightly faster way of writing derivatives. It takes 2 inputs:
%The first is the function your differentiating, the second is the variable 
%with respect to which you're differentiating. For example, if you want to
%write the the derivative of y with respect to x, you would type $\d{y}{x}$.
\renewcommand{\d}[2]{\dfrac{\mathrm{d}#1}{\mathrm{d}#2}}  

%This last macro creates a multicolumn list environment where the first input is the number of columns.
%Use this command when you plan on having so many parts to a problem, with each being very short to state
%that you would like to put the problems in several columns. An example of the syntax would be 
%\multilist{3}{
%\item first item
%...
%\item last item
%}
%This will create a list that displays in 3 columns. The 3 can be replaced by any natural number, but 2 and 3
%are the only one numbers likely to give readable output.
\newcommand{\multilist}[2] 
    {
        \begin{multicols}{#1}
            \begin{enumerate}
                #2
            \end{enumerate}
        \end{multicols}
    }
%%%For solutions sets:
%%%After you write the problem, the next line should be
%%%\solution{Type your solution in here}
\newcommand{\solution}{ 
  \medskip
  {\bf Solution:}
}     

\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\dx}{\frac{\delta}{\delta x}}
\newcommand{\ab}{\mathbf{a}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\Y}{\mathbf{Y}}
\newcommand{\bA}{\mathbf{A}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\Xs}{\tilde{\mathbf{X}}}
\newcommand{\xs}{\tilde{\mathbf{x}}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\sx}{\bar{\x}}
\newcommand{\tb}{\mathbf{t}}
\newcommand{\SG}{\mathbf{\Sigma}}
\newcommand{\ts}{\theta^*}
\newcommand{\tbi}{t_{b_i}}
\newcommand{\ptb}{\hat{t}_b}
\newcommand{\tv}{t_v}
\newcommand{\tvi}{t_{v_i}}
\newcommand{\ptv}{\hat{t}_v}
\newcommand{\ps}{\hat{s}}
\newcommand{\yh}{\hat{y}}
\newcommand{\M}{\mathbf{M}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\T}{\mathbf{T}}
\renewcommand{\S}{\mathcal{S}}
\renewcommand{\th}{t_0}
\renewcommand{\v}{\mathbf{v}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\W}{\mathbf{W}}
\newcommand{\p}{\mathbf{p}}
\newcommand{\wh}{\hat{\mathbf{w}}}
\newcommand{\wht}{\hat{\mathbf{w}}^T}
\newcommand{\whs}{\hat{\tilde{\mathbf{w}}}}
\newcommand{\whst}{\hat{\tilde{\mathbf{w}}}^T}
\newcommand{\ws}{\mathbf{w}^*}
\newcommand{\wst}{\mathbf{w}^{*T}}
\newcommand{\at}{\mathbf{a}^{T}}
\newcommand{\hth}{\hat{\theta}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\dbphi}{\Delta\bphi}
\newcommand{\C}{\mathbf{C}}
\newcommand{\gd}{\nabla}
\newcommand{\hs}{\nabla^2}
\newcommand{\Cb}{\bar{C}}
\renewcommand{\labelenumi}{\arabic{enumi})}
\renewcommand{\labelenumii}{\alph{enumii})}
\providecommand{\norm}[1]{\lVert#1\rVert}

\newcommand{\solutionline}{
\begin{center}
\line(1,0){400}
\end{center}
}
    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%This is where the document begins%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  
\begin{document}


%%%%%This stuff puts in the header and changes some spacing%%%%%%
\handout

\setlength{\parindent}{0pt}

The overall goal of this project is to develop a method for early detection of septic shock using continuous physiological data. We divide the problem into three parts: use topic modeling to learn features from the physiological data, derive a decision policy to decide what if any state the system should predict, and use a neural network to estimate the posterior probabilities for each state.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%Here is where the actual math begins%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{section}{0}
\section{Feature Discovery}
\subsection{Problem Definition}
The goal of this section is to detect hidden states over the time-series data for each patient, that would augment features being used by subsequent prediction systems. A natural model for such a system is the HMM. Using these hidden state sequences as input tokens of a document, we intend to run Topic models over all the patient records to see if there is any groups of states or any patten in state sequences that either explain or help predict the onset of septic shock.
\subsection{Related Works}
As noted in our proposal, the prognosis of septic shock in critically ill patients has a lot of variability. There is no single monolithic notion of septic shock \cite{Shavdia2007} . There are several methods to approach feature discovery in time series data of this nature. \cite{Esbroeck2012hrt}  applied symbolic aggregate approximation SAX \cite{Lin2003sax} on physiological time series data. More recently, Time series topic models have also been developed, \cite{SariaThesis2011} these work directly on continuous time domain signals and extract latent motifs. In our approach, we would like to investigate an HMM based approach, to allow a hidden state to emit a vector observation for a single time instance, where each element in the observation vector represents the observation of each channel of data (ECG, blood pressure, oxygen saturation etc).
\subsection{Contribution}
The dataset contains patient heart rate data at a frequency of 2 Hz. Each sample has been obtained by computing statistics over a 2 minute window from a the original heart rate data. Thus, every 120th sample represents statistics from a non-overlapping region from the original data. The first task is to extract these samples per patient record. We intend to find hidden states that best explain this lower resolution data. Each state of our HMM model will cover a wider time window, our current estimate for length of observation window per state is 30 minutes.\\
We also intend to extend the HMM to a coupled HMM where the second set of observations would represent blood pressure, temperature or oxygen saturation. Ideally the second set of observations would be in close time sync with the Heart rate data. This would be a factor in deciding which data stream (temperature, blood pressure or oxygen saturation) we would use for the second observation layer in the coupled HMM. Another factor would be the availability of these streams for all patient records. \\
\subsection{Learning Problem}
We propose to learn a HMM and then extend it to a coupled HMM. The 2 layers of observation are heart rate and blood pressure, temperature or oxygen saturation.  We intent to learn the states sequence that would best explain the patient records. Below is a representation of this coupled HMM, with each variable defined.\\
\begin{figure}[ht]
  \begin{center}
    \begin{tabular}{cc}
      \input{coupled_hmm}
    \end{tabular}
  \end{center}
  \caption{Coupled HMM model}
\label{fig:coupled_hmm_fig}
\end{figure}
\begin{align*}
O^1 &= o^1_{0}, \ldots,o^1_{T},   \text{sequence of heart rate observations (statistics from a 30 min time window)}\\
O^2 &=o^2_{0}, \ldots,o^2_{T},  \text{sequence of blood pressure or oxygen saturation}\\
Z &=  z_{0}, \ldots,z_{T}, \text{sequence of ${O^2}$ related states}\\
Y &=  y_{0}, \ldots,y_{T},  \text{sequence of ${O^1}$ related states}\\
\end{align*}
\subsubsection{State Priors}
Using appropriate priors and initial values for states is crucial to restrain the system from straying away from what might be explanatory data. We intend to encode some of our prior intuitions in this model in the following manner. Let ${Y}$ represent the states for heart rate observations over the patient record. We have the following insights from the data that we would like to encode.\\
1. Bootstrap from Patient Records: Each patient record has a time stamp representing the presence of SIRS, Sepsis, Severe Sepsis or Septic Shock. While this time stamps are not exact (that is, they are marked when the clinician happens to observe the symptoms and there is no guarantee that it was the precise moment of onset) we can still get statistics from the time region surrounding the clinicians observation of the symptoms. Using this technique we can get good initial guesses for statistics (such as means, and variances i.e. modeling the observation as a Guassian) for 4 states. It might also be preferable to model the observation given the state as a Beta distribution as we know that Heart rate can never be negative (which a gaussian in theory will allow).\\
2. Low Heart Rate Variability: Apart from the 4 states with we intend to bootstrap our model with states that have priors to restrict their parameters. One of the key insights regarding the onset of septic shock is reduction in heart rate variability. This informs us that one of the statistics that we need to compute from each 30 min time window should be a good indication of variability. Thus, simply getting mean heart rate for a 30 min duration would not be a good statistic. We intend to initialize a "Low Variability" state to capture this trend.
3. High Heart Rate Variability: The opposite state from the pervious would be the "High Variability" state where the 30 min window shows significant variation.\\
4. Reduction in Variability State: This state would be initialized such that there is variability across the earlier samples which slowly decline as we reach the end of the time window. One way to achive this is to place a prior over the slope of a statistic such as change in variable from beginning of window to the end. A negative slope indicates reduction of variability.\\
Similar set of priors and initialization methods can be applied to the states corresponding to the ${Z}$ chain as well. It's important to note that some experimentation would be required to get a sense of these priors, they should be restrictive enough to coerce the model in the general direction we want, but also allow for discovery of states, and states sequences. We do not have plans for priors over state transitions.



\section{Reliable Classification}

\subsection{Problem Definition}
\begin{figure}[ht]
  \begin{center}
    \begin{tabular}{cc}
      \input{model_reclas}
    \end{tabular}
  \end{center}
  \caption{Reliable Classifier model as a Bayesian network}
\label{fig:reclas_bnet}
\end{figure}


\begin{align*}
X &= x_0, x_1, \ldots, x_T \text{ sequence of observations}\\
R &= r_0, r_1 \ldots, r_T \text{ sequence of clinical interventions}\\
\hat{Y} &= \yh_0, \yh_1, \ldots, \yh_T \text{ sequence of predicted class labels, $\yh_i \in \{1,\ldots, C\}$}\\
Y&=y_0,y_1,\ldots,y_T \text{ sequence of true labels, $y_i \in \{1,\ldots, C\}$}\\
U&=u_0,u_1,\ldots,u_T \text{ a decision policy, $u_i \in \{1,\ldots, C, C+1\}$}\\
S &\in \R^{C+1 \times C \times T}, S_{i,j}^{(t)} \text{ is the cost of choosing label $i$ instead of label $j$ at time $t$}\\
\bar{C} &= \{1,\ldots, C\} \text{ set of possible classes}\\
\hat{C} &= \{1,\ldots, C,C+1\} \text{ set of possible decisions}
\end{align*}

Our goal is to learn a decision policy that allows us to make the optimal decision at time $T$ given a sequence of observations and a user-defined cost function.

At each time $t$ the system either chooses the class $c \in \{1,\ldots, C\}$ that minimizes the expected loss over the time sequence $0\ldots T$ or it refuses to make a decision, corresponding to choosing $c = C+1$. Each $\yh_t$ is a probability distribution over possible the possible classes $\bar{C}$. If there is a clinical intervention $r_t$ at the current time $t$, e.g.\ a doctor prescribes pressors or performs some other action that provides a diagnosis, we define $P(y_t=j)$ to be $P(y_t=j|r_t)$. However, since we are performing a continuous monitoring task, the majority of time points will not have a clinical intervention associated with it. In these cases we use the distribution from the classifier $\yh_t$ and define $P(y_t=j)$ to be $P(\yh_t=j|x_t, y_{t-1})$. We then feed the distribution $y_t$ to our classifier so that the predicted distribution over classes $\yh_{t+1}$ incorporates knowledge about clinical interventions into the classification process. Instead of defining the distribution $y_t$ as either $r_t$ or $\yh_t$, we could instead define it as a mixture of the two distributions based on our confidence in the classifier's predictions. 

The decision $u_t$ is influenced by the distribution over all possible class labels $y_t$ and the previous decision $u_{t-1}$. The motivation for allowing the previous decision to influence the current decision is two-fold. First this can act as a smoothing function and capture the intuition that patients show a gradual transition from one disease state to the next, and prevents situations like repeatedly alternating between two disease states instead of staying in one state until the classifier is sufficiently confident to advance to a new disease state. The second benefit of this dependency between successive decisions is that it allows us to prevent overly long rejection periods, where the classifier continuously refuses to predict. We can do this by progressively down-weighting the probability of rejection given the history of rejection.

\subsection{Related Work}

By adding the notion of rejection (i.e.\  refusing to predict), the classifier is able to avoid misclassification, by instead refusing to predict. As stated by Chow \cite{Chow1970} the optimal strategy is one that minimizes the rate of rejection. For a single time point, Chow shows how to formulate the decision policy of when to reject in terms of a rejection threshold. He similarly formulates the error in terms of that same threshold by noting that the expected cost of error is the expected cost of rejecting minus the expectation of being correct. This rejection threshold can then relate the expected cost of rejecting to the expected cost of misclassification and allow the user to trade off between them. 

Grall-Ma\"{e}s and  Beauseroy \cite{GrallMaes2009} extend the optimal decision framework by allowing an observation to be assigned to a subset of the classes. Assigning an observation to the set of all classes corresponds to refusing to predict and assigning an observation to a set with only one class corresponds to predicting that class without ambiguity. Grall-Ma\"{e}s and  Beauseroy derive the optimal decision policy for assigning an observation to a set given a cost matrix and performance constraints. Performance constraints are, for example, the false positives for this class must be below a given threshold or the false positives for a given subset must be below this level.

Santaniello et al.\ \cite{Santaniello2012} formulate a transition detection problem where they learn a decision policy to decide when a change of state has occurred in a time sequence. In particular, they derive a decision policy for quickest detection, where they want to detect the change point as early as possible with sufficient confidence. To encourage early detection, they include the expected distance of the current time from the actual change time in the cost function. 


\subsection{Contribution}
For the task of sepsis prediction and continuous patient monitoring in general, we want to derive a generic optimal decision policy for time series data where we allow the system to refuse to predict. Moreover, we allow for a user-defined cost function that can be asymmetric, e.g.\ assigning different costs for false positives or negatives for different classes, and that can change over time. This task is different than transition detection in that we do not assume there is only one transition point and we do not assume that the subject even has to transition.


\subsection{Simulation}

In order to test the reliable classification, we generate synthetic data from four overlapping Gaussians, where each Gaussian corresponds to a different class.

We use Kevin Murphy's BayesNet and CRF Matlab toolkits to implement a model to compute $\hat{Y}$ for the synthetic data. We then use these marginal probabilities at each time step to implement the learning problem as described below. For the simulation we do address the situation where we have a doctor intervention (i.e.\ $R=\emptyset$). 

We will consider how different parameterizations of the cost matrix allow us to trade off between the cost of misclassification and the cost of refusing to predict. We will also investigate how to set the cost matrix to encourage early detection.

\subsection{Learning Problem}
Our goal is to learn a decision policy that allows us to minimize the expected loss over the entire time sequence of observations.
The expected posterior loss at time $t$ of making decision $u_t=i$ given that the true label is $y_t=j$ and the previous decision was $u_{t-1}=h$ as follows:

\begin{align}
\E[L(u_t|y_t, u_{t-1})] &= \min_{u_t} \Big\{ \sum_{i \in \hat{C}} \sum_{j \in \bar{C}} S_{i,j}^{(t)} P(y_t=j)P(u_t=i|u_{t-1})\I(u_t=i)\Big\}\\
&= \min_{u_t \in \hat{C}} \Big\{ \sum_{j \in \bar{C}} S_{u_t,j}^{(t)} P(y_t=j)P(u_t|u_{t-1})\Big\}
\label{eqn:exploss}
\end{align}

We use dynamic programming to learn the optimal decision policy over the time sequence, with a discounting factor $\beta \in [0,1]$ to adjust the importance of past observations.

Let $V(y_T)$ be the value of the expected posterior loss minimized by a decision policy $\{u_t\}_{t=0}^{T}$. At time $T$ we make the decision $u_T$ that is the argmin of (\ref{eqn:bellman}).

\begin{align}
V(y_T) &= \min_{\{u_t\}_{t=0}^{T}} \Big\{ \sum_{t=0}^T \beta^{T-t}\E[L(u_t|y_t, u_{t-1})] \Big\}\\
&= \min_{u_T \in \hat{C}} \Big\{  \beta^{0}\E[L(u_T|y_T, u_{T-1})] + \min_{\{u_t\}_{t=0}^{T-1}} \beta \sum_{t=0}^{T-1} \beta^{T-1-t}\E[L(u_t|y_t, u_{t-1})] \Big\}\\
&= \min_{u_T \in \hat{C}} \Big\{  \E[L(u_T|y_T, u_{T-1})] + \beta V(y_{T-1})\Big\} \label{eqn:bellman}
\end{align}

From this we see that the system will either make the decision $u_T = c \in \bar{C}$ that minimizes the expected loss over the sequence or it will refuse to predict, equivalent to choosing $u_T = C+1$. 

Computing the expected loss with dynamic programming, where we maintain a vector of the class costs from the previous time step, requires $C(C+1)+4$ operations at each time point, so the overall complexity is $O(TC^2)$. For space efficiency, it is only necessary to maintain the cost vector from the previous time step.


\section{Neural Networks for Sepsis Prediction}

\subsection{Introduction}

\begin{figure}[h!]
  \caption{Schematic of a simple neural network}
  \centering
    \includegraphics[width=1.0\textwidth]{nn_plots/nn}
\end{figure}

The goal of this section is to train neural networks to estimate the probability of developing a disease state given a sequence of
physiological data. Here, the task is early prediction of septic shock in ICU patients with a documented infection. Heart rate is used as input to the neural network. We estimate the probability of an ICU patient developing a form of sepsis $P(sepsis \mid S)$ where $S$ is a window of the 
heart rate timeseries. This model is motivated by the state of the art performance produced by Deep Neural Networks in a number of domains.


\subsection{Related Work}

The application of neural networks to the the task of sepsis prediction appears relatively unexplored. However, neural network techniques have been successfully applied to classification and prediction on other physiological time series. \cite{wulsin2011modeling} applied Deep Belief Networks (DBNs), a method related to Deep Neural Networks (DNN), to the task of anomaly detection in clinical EEG records. The group found that 
DBNs produced comparable results to other state of art methods, but significantly faster. They found
that using the raw EEG waveform showed improved performance in an
anomaly detection task over engineered features.
These results underscore the advantage of deep learning methods in 
automatically uncovering useful features. \\

To obtain adequate performance a body of techniques and tricks need to be considered. In \cite{hinton2012deep} speech recognition groups at Google, Microsoft, IBM and University of Toronto share various techniques for improving neural network performance. For instance, one should consider techniques for
preventing overfitting by certain restrictions on weight updating and smart initialization of weights.

\subsection{Approach}

Equation (6) describes
the output of a neuron $j$ given the weighted commulative input $x_j$ (7). 
\begin{align}
y_{j} = \frac{1}{1+e^{-x_{j}}} \\
x_{j} = b_{j} + \sum_{i}y_{i}w_{ij} \\
p(sepsis \mid S) = \frac{1}{1 + exp(x_{sepsis})}
\end{align}

\begin{align}
J = -\sum_{j} t_{j} log(y_{j})
\end{align} \\
\\
\begin{align}
\nabla J(w) = -\sum_{j} (y_{j} - t_{j}) x_{j} \\
input = \bar{x}_{1}, \sigma_{1}, \bar{x}_{2}, \sigma_{2}, ... ,\bar{x}_{60}, \sigma_{60}
\end{align} \\

Equation (8) represents the probability
of sepsis given some some sequence of physiological signals $S$. With only two classes, this is equivalent to the
\textit{softmax} function. The 
target function is (9) where $t_{j}$ is the correct class label (eg, sepsis or not sepsis). Equation (10)
is the derivative at the output layer. Input to the network is a one hour frame in the form of a 2x60 vector of mean heart rate $\bar{x}$
and heart rate standard deviation $\sigma$. Each statistic is measured from a one minute interval in the original 2 Hz data.
\begin{align}
\eta = \frac{A}{\frac{epoch_{j}}{epoch_{max}} + 1} \\
w_{i,j} \sim N(0, \frac{1}{\sqrt{inputs_{j}}}) \\
w_{i,j} \leftarrow \frac{w_{i,j}}{\sigma_{j}}
\end{align}
\\
Neural networks require careful weight initialization, pretraining (for deep networks), topology and other considerations described in \cite{vesely2013sequence, hinton2012deep}. To help guarantee convergence, we have a learning rate which decreases as the number of epochs increase (12). Weights are drawn from a normal distribution (13), which we found offered greater stability over alternative distributions, such as uniform. After two or three hidden layers, the network suffers from oversaturation, which is characterized by a very large range of values from the
transfer functions in (8), resulting in numerical overflow and underflow. To combat this issue, we simply divide by the standard deviation
of the weights in the oversaturated layer during training (14).
\\
We use a standard batch gradient descent backpropagation algorithm to train the network. We experimented with stochastic gradient descent and didn't
notice much of an advantage. Moreover, it's easier to track the training process in batch gradient descent: at each epoch, we calculate
the loss function (9) and in the batch variation, we can be sure that the network's parameters have been altered by every training example.

\subsection{Preliminary Results and Evaluation}

\begin{figure}
        \centering
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/loss2}
                \caption{Cross entropy loss vs. number of epochs.}
                \label{fig:entropy}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/dev2}
                \caption{Development (validation) set error rate vs. number of epochs.}
                \label{fig:dev}
        \end{subfigure}
\caption{Typical results for a network with 120 input nodes, 1 hidden layer with 100 nodes, and one output layer with 1 node.}\label{fig:loss_dev}
\end{figure}

In figure \ref{fig:loss_dev} we present typical results for a network with 120 input nodes, 1 hidden layer with 100 nodes, and a single output layer with 1 node. Given the current framework, we didn't see an advantage in using more than 1 hidden layer. The development (validation) error rate
in ~\ref{fig:dev} is the classification error rate. To obtain classification from the conditional probabilities generated by the network, we
map probabilities at or above 0.5 to class 1, and probabilities below 0.5 to class 0.
\\
\\
To train the network in figure ~\ref{fig:loss_dev} we do not use a sliding window over the entire time series for each patient. Instead, we 
first separate the data into two categories: SIRS, and severe sepsis and septic shock. From the SIRS category we randomly select some
number of 1 hour frames. From the severe sepsis and septic shock category, we only select the one hour frames which immediately precede 
the onset of the disease. While this setup isn't ideal, it plays an important step in the goal of more sophisticated prediction, by
demonstrating that we can distinguish between certain disease states by using just heart rate.

\begin{figure}
        \centering
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/probs_c0_1}
                \caption{}
                \label{fig:c0_0}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/probs_c1_2}
                \caption{}
                \label{fig:c0_0}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/probs_c0_3}
                \caption{}
                \label{fig:c0_0}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/probs_c1_3}
                \caption{}
                \label{fig:c0_0}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/probs_c0_4}
                \caption{}
                \label{fig:c0_0}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{nn_plots/probs_c1_4}
                \caption{}
                \label{fig:c0_0}
        \end{subfigure}
\caption{Probability of sepsis from beginning to end of individual dev (validation) records. The left column (blue) corresponds to patients who only have SIRS, while the right column (red) corresponds to those who develop either severe sepsis or septic shock by the end of the time series. These results are due to a network with 120 input nodes and 100 hidden layer nodes.}\label{fig:probs}
\end{figure}
The goal of this section is the early prediction of septic shock, rather than just the classification of it in static window. Figure ~\ref{fig:probs}
illustrates preliminary results for this task. In each patient, we slide a window over the time series, and generate $p(sepsis \mid frame)$. Before calculating these probabilities, the network was trained using the techniques discussed in the previous session. Further, results were
only reported for networks which achieved an error rate of .30 or less on the dev set (see ~\ref{fig:dev}). 
\\
\\
Ideally, we would like to see that the $p(sepsis \mid frame_{t})$ increases over time for the patients with severe sepsis and septic shock
and remains relatively constant for patients with SIRS. Additionally, it would be desirable for the $p(sepsis \mid frame_{t})$ to be 
higher in general for those who go on to develop septic shock or severe sepsis than those who develop SIRs. Given our preliminary
data, it is unclear if we can affirm either of these statements.   

\subsection{Discussion}

In \textit{Approach} we describe that the input to the network is a one hour frame of mean heart rate and heart rate standard deviation.
The two features are extracted from 1 minute intervals in the original heart rate. Initially, we attempted to use the raw 2 Hz heart rate directly,
but this suffered from slow training and near chance dev set accuracy. We also extracted these features at intervals of 
15 and 7.5 minutes. Due to such extreme downsampling, the data was much faster to process, but accuracy was no better than chance. Experimentally, we found that features extracted at one minute intervals retained enough structure in the data for learning to occur (see \textit{Preliminary Results}) while being computationally tractable.
 
\subsection{Future Work}

We observed numerical instability and overfitting in networks with several layers. However, we never implemented the sophisticated pretraining
methods characteristic of DNNs. After incorporating these techniques, we will explore what, if any, advantage deep neural networks provide
us in this domain.
\\
\\
Our current framework can accurately classify a one hour frame of heart rate as septic or not septic when the input is unambiguous. However,
when used to predict the future onset of sepsis, results under this system are inconclusive (see \textit{Preliminary Results}).
\\
\\
It is possible that heart rate alone doesn't have enough structure to adequately predict septic shock hours in advance. We will incorporate
additional physiological signals, such as blood pressure and respiratory rate as features to the neural network.

\subsection{Data}

The data for this task consists of heart rate sampled at 2 Hz derived from the MIMIC II Waveform Database. For neural network training, we use a 486 record subset which 
serves as the training, dev, and test sets. 
Each record contains heart rate for an ICU patient with SIRS, severe sepsis or septic shock, with at least
12 hours preceding the event.

\bibliographystyle{plain}

\bibliography{PhysMod,dnn,ref}

\end{document}
